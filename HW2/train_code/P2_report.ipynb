{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UNet import *\n",
    "from utils import *\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/3184638812.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./hw2_data/face/UNet.pt\"))\n"
     ]
    }
   ],
   "source": [
    "model = UNet()\n",
    "model.load_state_dict(torch.load(\"./hw2_data/face/UNet.pt\"))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "noise_dir = \"./hw2_data/face/noise\"\n",
    "DDIM_STEP = 50\n",
    "DDPM_STEP = 1000\n",
    "\n",
    "STEP = -(DDPM_STEP // DDIM_STEP)\n",
    "\n",
    "\n",
    "beta = beta_scheduler(1001)\n",
    "alpha = 1 - beta\n",
    "alpha_cum = torch.cumprod(alpha, dim=0)\n",
    "\n",
    "def generate(eta=0.0):\n",
    "    for path in os.listdir(noise_dir):\n",
    "        path = os.path.join(noise_dir, path)\n",
    "\n",
    "        img = torch.load(path)\n",
    "        \n",
    "        for t in tqdm(range(DDPM_STEP + STEP + 1, STEP + 1, STEP)):\n",
    "            with torch.no_grad():\n",
    "                eps = model(img.cuda(), torch.tensor(t).cuda())\n",
    "\n",
    "            # alpha_t = torch.full((img.shape[0], 1, 1, 1), (1 - beta_scheduler(1001)[t])).cuda()\n",
    "            # if t + STEP <= DDPM_STEP:\n",
    "            #     alpha_t_minus_1 = torch.full((img.shape[0], 1, 1, 1), (1 - beta_scheduler(1001)[t + STEP])).cuda()\n",
    "            # else:\n",
    "            #     alpha_t_minus_1 = torch.full((img.shape[0], 1, 1, 1), 1.0).cuda()\n",
    "\n",
    "            alpha_t = alpha_cum[t]\n",
    "            alpha_t_minus_1 = alpha_cum[t + STEP if t > -STEP else 0] \n",
    "            # alpha_t_minus_1 = alpha_cum[t + STEP] if t > -STEP else torch.tensor(1)\n",
    "\n",
    "            sigma_t = eta * torch.sqrt((1 - alpha_t_minus_1) / (1 - alpha_t) * (1 - alpha_t / alpha_t_minus_1))\n",
    "\n",
    "            random_noise = sigma_t * torch.randn_like(img)\n",
    "            to_xt = (torch.sqrt(1 - alpha_t_minus_1 - sigma_t ** 2) * eps)\n",
    "            pred_x0 = ((img - torch.sqrt(1 - alpha_t) * eps) / torch.sqrt(alpha_t))\n",
    "\n",
    "            # pred_x0 = torch.clamp(pred_x0, -1.0, 1.0)\n",
    "            img = torch.sqrt(alpha_t_minus_1) * pred_x0 + to_xt + random_noise\n",
    "\n",
    "            # img =  torch.sqrt(alpha_t_minus_1 / alpha_t) * img - torch.sqrt(alpha_t_minus_1 * ( 1 - alpha_t) / alpha_t) * eps + torch.sqrt(1 - alpha_t_minus_1 - sigma_t ** 2) * eps + sigma_t * torch.randn_like(img)\n",
    "        # img = torch.clamp(img, -1.0, 1.0)\n",
    "        min_value = img.min()\n",
    "        img = img - min_value\n",
    "        max_value = img.max()\n",
    "        img /= max_value\n",
    "\n",
    "        save_image(img, os.path.join(\"p2_outdir\", f\"{eta}_\"+ os.path.basename(path).replace('.pt', \".png\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate eta 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/327528816.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  img = torch.load(path)\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.07it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.09it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.24it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.23it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.21it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.30it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.49it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.65it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.47it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.55it/s]\n"
     ]
    }
   ],
   "source": [
    "generate(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "def load_images2tensor(root_dir):\n",
    "    img_list = os.listdir(root_dir)\n",
    "    img_list.sort()\n",
    "    img = []\n",
    "    for l in img_list:\n",
    "        l = os.path.join(root_dir, l)\n",
    "        i = torchvision.io.read_image(l)\n",
    "        img.append(i.unsqueeze(0))\n",
    "\n",
    "    return torch.cat(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT = load_images2tensor(\"hw2_data/face/GT\")\n",
    "Pd = load_images2tensor(\"tmp_eta_0/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 256, 256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((Pd - GT) ** 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4086) tensor(0.4086)\n"
     ]
    }
   ],
   "source": [
    "print(torch.mean(((Pd - GT) ** 2).float()), nn.MSELoss()(Pd.float(), GT.float()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Others eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/327528816.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  img = torch.load(path)\n",
      "100%|██████████| 50/50 [00:01<00:00, 30.18it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.30it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.34it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.42it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.41it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.42it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.38it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.33it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.00it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.87it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.22it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.22it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 81.78it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.10it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.43it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.36it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.16it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.87it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.80it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.90it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.84it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.82it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.92it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.94it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 83.53it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.92it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.99it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.82it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.86it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.97it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.13it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.03it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.96it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.96it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.90it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 28.91it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 35.20it/s] \n",
      "100%|██████████| 50/50 [00:02<00:00, 19.83it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.86it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.88it/s]\n"
     ]
    }
   ],
   "source": [
    "generate(0.25)\n",
    "generate(0.5)\n",
    "generate(0.75)\n",
    "generate(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.25\n",
      "0.5\n",
      "0.75\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "while j <= 1:\n",
    "    print(j)\n",
    "    j += 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "images = []\n",
    "j = 0\n",
    "while j <=1 :\n",
    "    t = []\n",
    "    for i in range(4):\n",
    "        t.append(T.ToTensor()(Image.open(os.path.join(\"p2_outdir\", f\"{j if j != 1.0 else '1'}_{i:02}.png\"))).unsqueeze(0))\n",
    "    images.append(torch.concat(t))\n",
    "    j += 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.concat(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = make_grid(images, nrow=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(grid, \"p2_outdir/out.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product(x, y):\n",
    "        return torch.sum(x * y, dim=(1, 2, 3))\n",
    "\n",
    "def get_angle(x, y):\n",
    "    return torch.arccos(\n",
    "        inner_product(x, y) / (\n",
    "            (inner_product(x, x) ** 0.5) * (inner_product(y, y) ** 0.5)\n",
    "        )\n",
    "    )[:, None, None, None]\n",
    "\n",
    "def get_interpolation_weight(start, end, n_points):\n",
    "    return torch.arange(start, end, n_points)[:, None, None, None].cuda()\n",
    "\n",
    "\n",
    "def _get_spherically_interpolated_rand_noise(n_points):\n",
    "    rand_noise1 = torch.load(\"hw2_data/face/noise/00.pt\")\n",
    "    rand_noise2 = torch.load(\"hw2_data/face/noise/01.pt\")\n",
    "    ang = get_angle(rand_noise1, rand_noise2)\n",
    "    weight = get_interpolation_weight(0, 1.1, n_points)\n",
    "\n",
    "    x_weight = torch.sin((1 - weight) * ang) / torch.sin(ang)\n",
    "    y_weight = torch.sin(weight * ang) / torch.sin(ang)\n",
    "    return x_weight * rand_noise1 + y_weight * rand_noise2\n",
    "\n",
    "def interpolate_in_latent_space(n_points=0.1):\n",
    "    rand_noise = _get_spherically_interpolated_rand_noise(\n",
    "        n_points=n_points\n",
    "    )\n",
    "    \n",
    "    return rand_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0\n",
    "def gen_special_img(noises):\n",
    "    result = []\n",
    "    for noise in noises:\n",
    "        img = noise.unsqueeze(0)\n",
    "            \n",
    "        for t in tqdm(range(DDPM_STEP + STEP, STEP, STEP)):\n",
    "            with torch.no_grad():\n",
    "                eps = model(img.cuda(), torch.tensor(t).cuda())\n",
    "\n",
    "            # alpha_t = torch.full((img.shape[0], 1, 1, 1), (1 - beta_scheduler(1001)[t])).cuda()\n",
    "            # if t + STEP <= DDPM_STEP:\n",
    "            #     alpha_t_minus_1 = torch.full((img.shape[0], 1, 1, 1), (1 - beta_scheduler(1001)[t + STEP])).cuda()\n",
    "            # else:\n",
    "            #     alpha_t_minus_1 = torch.full((img.shape[0], 1, 1, 1), 1.0).cuda()\n",
    "\n",
    "            alpha_t = alpha_cum[t]\n",
    "            alpha_t_minus_1 = alpha_cum[t + STEP if t > -STEP else 0] \n",
    "            # alpha_t_minus_1 = alpha_cum[t + STEP] if t > -STEP else torch.tensor(1)\n",
    "\n",
    "            sigma_t = eta * torch.sqrt((1 - alpha_t_minus_1) / (1 - alpha_t) * (1 - alpha_t / alpha_t_minus_1))\n",
    "\n",
    "            random_noise = sigma_t * torch.randn_like(img)\n",
    "            to_xt = (torch.sqrt(1 - alpha_t_minus_1 - sigma_t ** 2) * eps)\n",
    "            pred_x0 = ((img - torch.sqrt(1 - alpha_t) * eps) / torch.sqrt(alpha_t))\n",
    "\n",
    "            # pred_x0 = torch.clamp(pred_x0, -1.0, 1.0)\n",
    "            img = torch.sqrt(alpha_t_minus_1) * pred_x0 + to_xt + random_noise\n",
    "\n",
    "            # img =  torch.sqrt(alpha_t_minus_1 / alpha_t) * img - torch.sqrt(alpha_t_minus_1 * ( 1 - alpha_t) / alpha_t) * eps + torch.sqrt(1 - alpha_t_minus_1 - sigma_t ** 2) * eps + sigma_t * torch.randn_like(img)\n",
    "        # img = torch.clamp(img, -1.0, 1.0)\n",
    "        min_value = img.min()\n",
    "        img = img - min_value\n",
    "        max_value = img.max()\n",
    "        img /= max_value\n",
    "\n",
    "        result.append(img)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/3628542764.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rand_noise1 = torch.load(\"hw2_data/face/noise/00.pt\")\n",
      "/tmp/ipykernel_4791/3628542764.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rand_noise2 = torch.load(\"hw2_data/face/noise/01.pt\")\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.71it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.29it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.64it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.75it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.70it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.95it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.25it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 69.75it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.57it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.62it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.62it/s]\n"
     ]
    }
   ],
   "source": [
    "result = gen_special_img(interpolate_in_latent_space(0.1))\n",
    "result = torch.cat(result)\n",
    "\n",
    "img = make_grid(result, nrow=11)\n",
    "save_image(img, \"p2_outdir/out1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_noises(step=0.1):\n",
    "    rand_noise1 = torch.load(\"hw2_data/face/noise/01.pt\")\n",
    "    rand_noise2 = torch.load(\"hw2_data/face/noise/00.pt\")\n",
    "\n",
    "    alpha = torch.arange(0, 1.1, step)[:, None, None, None].cuda()\n",
    "    beta = 1 - alpha\n",
    "\n",
    "    return rand_noise1 * alpha + rand_noise2 * beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/2920519834.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rand_noise1 = torch.load(\"hw2_data/face/noise/01.pt\")\n",
      "/tmp/ipykernel_4791/2920519834.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rand_noise2 = torch.load(\"hw2_data/face/noise/00.pt\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 3, 256, 256])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_noises().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4791/2920519834.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rand_noise1 = torch.load(\"hw2_data/face/noise/01.pt\")\n",
      "/tmp/ipykernel_4791/2920519834.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rand_noise2 = torch.load(\"hw2_data/face/noise/00.pt\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 19.87it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.53it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.60it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.98it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.86it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.68it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.63it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.78it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 76.13it/s] \n",
      "100%|██████████| 50/50 [00:02<00:00, 19.42it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.81it/s]\n"
     ]
    }
   ],
   "source": [
    "result = gen_special_img(linear_noises(0.1))\n",
    "result = torch.cat(result)\n",
    "\n",
    "img = make_grid(result, nrow=11)\n",
    "save_image(img, \"p2_outdir/out2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
